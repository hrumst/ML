{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dqn-pong.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrumst/ML/blob/master/dqn_pong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipwdFHUVB5qG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import gym\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WoSzJUgB5qJ",
        "colab_type": "text"
      },
      "source": [
        "## Load GYM environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "RO8UWiE4B5qK",
        "colab_type": "code",
        "outputId": "7497bc6b-7316-4811-d45e-703b0960c49a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "env = gym.make('Pong-v0')\n",
        "\n",
        "STATE_SHAPE = env.observation_space.shape\n",
        "NUM_ACTIONS = env.action_space.n\n",
        "\n",
        "print('Actions: {}'.format(NUM_ACTIONS))\n",
        "print('States shape: {}'.format(STATE_SHAPE))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actions: 6\n",
            "States shape: (210, 160, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tcQQwNh7nUZ",
        "colab_type": "code",
        "outputId": "6552c3a8-3ae2-4178-f43e-ee7a364a065c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "env.__dict__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_elapsed_steps': 0,\n",
              " '_episode_started_at': None,\n",
              " '_max_episode_seconds': None,\n",
              " '_max_episode_steps': 10000,\n",
              " 'action_space': Discrete(6),\n",
              " 'env': <gym.envs.atari.atari_env.AtariEnv at 0x7f2276147d30>,\n",
              " 'metadata': {'render.modes': ['human', 'rgb_array']},\n",
              " 'observation_space': Box(210, 160, 3),\n",
              " 'reward_range': (-inf, inf)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNiSdKeo8I4O",
        "colab_type": "code",
        "outputId": "c326fc23-5741-4eae-fafb-1a1de66b9ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "env.observation_space.shape[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHaEq-ExGjp5",
        "colab_type": "text"
      },
      "source": [
        "## Example of a state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HycCupurCLXM",
        "colab_type": "code",
        "outputId": "6e713e2c-aef2-4152-8629-5c3e35b42025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "s = env.reset()\n",
        "_=plt.imshow(s)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM4AAAD8CAYAAAA/rZtiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUSl-luBMors",
        "colab_type": "text"
      },
      "source": [
        "## DQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMKyAI5GLN1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train a DQN model here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE8rG50K3cKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Conv2D, Lambda, MaxPooling2D, Conv2DTranspose, concatenate, Dropout, BatchNormalization, Dense, Flatten\n",
        "from keras.models import Model, load_model, Sequential\n",
        "\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    inputs = Input((210, 160, 3))\n",
        "    c1 = Conv2D(128, (3, 3), activation='elu', padding='same') (inputs)\n",
        "    c1 = Conv2D(128, (3, 3), activation='elu', padding='same') (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "    f1 = Flatten()(p1)\n",
        "    out = Dense(2, activation='sigmoid')(f1)\n",
        "    model = Model(inputs=[inputs], outputs=[out])\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx1Bmmi77FOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import deque\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "DISCOUNT = .9\n",
        "MEMORY_LIMIT = 5000\n",
        "memory = deque([], maxlen=MEMORY_LIMIT)\n",
        "\n",
        "def reset_memory():\n",
        "    memory = deque([], maxlen=MEMORY_LIMIT)\n",
        "\n",
        "UP_ACTION = 2\n",
        "DOWN_ACTION = 3\n",
        "ACTIONS = [UP_ACTION, DOWN_ACTION]\n",
        "ACT_DICT = {\n",
        "    '2': 0,\n",
        "    '3': 1\n",
        "}\n",
        "EXPLORE_COEF = .1\n",
        "\n",
        "def choose_action(model, state):\n",
        "    if np.random.rand() <= EXPLORE_COEF:\n",
        "        return np.random.randint(0, len(ACTIONS))\n",
        "    q = model.predict(state.reshape(1, state.shape[0], state.shape[1], state.shape[2]))\n",
        "    return ACTIONS[np.argmax(q[0])]\n",
        "\n",
        "def prep_batch(model, batch_size):\n",
        "    if batch_size > MEMORY_LIMIT:\n",
        "        Warning('batch size should not be larger than max memory size. Setting batch size to memory size')\n",
        "        batch_size = MEMORY_LIMIT\n",
        "\n",
        "    batch_size = min(batch_size, len(memory))\n",
        "\n",
        "    inputs = []\n",
        "    targets = []\n",
        "    batch = random.sample(list(memory), batch_size)\n",
        "    random.shuffle(batch)\n",
        "    for state, action, next_state, reward in batch:\n",
        "        print('ACT:', action)\n",
        "        inputs.append(state)\n",
        "        target = model.predict(state.reshape(1, state.shape[0], state.shape[1], state.shape[2]))[0]\n",
        "\n",
        "        if reward:\n",
        "            target[ACT_DICT[str(action)]] = reward\n",
        "        else:\n",
        "            print(111)\n",
        "            # reward + gamma * max_a' Q(s', a') bellman equation\n",
        "            model_sa = np.max(model.predict(next_state.reshape(1, next_state.shape[0], next_state.shape[1], next_state.shape[2]))[0])\n",
        "            target[ACT_DICT[str(action)]] = reward + DISCOUNT * model_sa\n",
        "            print(112)\n",
        "        targets.append(target)\n",
        "    \n",
        "    return np.vstack(inputs), np.vstack(targets)\n",
        "\n",
        "def replay(model, batch_size):\n",
        "    inputs, targets = prep_batch(model, batch_size)\n",
        "    loss = model.train_on_batch(inputs, targets)\n",
        "    return loss\n",
        "\n",
        "def reset_tf_session():\n",
        "    curr_session = tf.get_default_session()\n",
        "    # close current session\n",
        "    if curr_session is not None:\n",
        "        curr_session.close()\n",
        "    # reset graph\n",
        "    K.clear_session()\n",
        "    # create new session\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    s = tf.InteractiveSession(config=config)\n",
        "    K.set_session(s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiOBPXjVGnLR",
        "colab_type": "text"
      },
      "source": [
        "## Virtual display and video recording for Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kzmt2e5jEbX6",
        "colab_type": "code",
        "outputId": "90e4b504-a681-476e-fabf-22fd502cc5a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "RECORD_VIDEO = True\n",
        "\n",
        "if RECORD_VIDEO:\n",
        "  \n",
        "    !pip install pyvirtualdisplay > /dev/null 2>&1\n",
        "    !apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "\n",
        "    from pyvirtualdisplay import Display\n",
        "    display = Display(visible=0, size=(1400, 900))\n",
        "    display.start()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOOpS7r80-zj",
        "colab_type": "code",
        "outputId": "eabe0900-edb9-48a5-a914-20910244cdbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 6500\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "if RECORD_VIDEO:\n",
        "    from gym.wrappers import Monitor\n",
        "    env_sim = Monitor(env, './video', force=True)\n",
        "else:\n",
        "    env_sim = env\n",
        "\n",
        "\n",
        "# keep track of past record_len results\n",
        "record_len = 100\n",
        "record = deque([], record_len)\n",
        "\n",
        "reset_tf_session()\n",
        "model = make_model()\n",
        "print(model.summary())\n",
        "reset_memory()\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    state = env_sim.reset()\n",
        "    reward = 0\n",
        "    loss = 0\n",
        "\n",
        "    # q = model.predict(state.reshape(1, state.shape[0], state.shape[1], state.shape[2]))\n",
        "    # print(state.reshape(1, state.shape[0], state.shape[1], state.shape[2]).shape)\n",
        "    # print()\n",
        "    # # print(len(q[0]), len(q[0][0]), len(q[0][0][0]))\n",
        "    # break\n",
        "\n",
        "    while reward == 0:\n",
        "        env_sim.render()\n",
        "        action = choose_action(model, state)\n",
        "\n",
        "        prev_state = state\n",
        "        state, reward, done, _ = env_sim.step(action)\n",
        "        memory.append((prev_state, action, state, reward))\n",
        "        replay(model, BATCH_SIZE)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        sys.stdout.flush()\n",
        "        sys.stdout.write('epoch: {:04d}/{} | loss: {:.3f} | win rate: {:.3f}\\r'.format(i+1, epochs, loss, sum(record)/len(record) if record else 0)) \n",
        "    record.append(reward if reward == 1 else 0)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 210, 160, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 210, 160, 128)     3584      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 210, 160, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 105, 80, 128)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1075200)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 2150402   \n",
            "=================================================================\n",
            "Total params: 2,301,570\n",
            "Trainable params: 2,301,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: 2 root error(s) found.\n  (0) Failed precondition: Failed to allocate scratch buffer for device 0\n\t [[{{node _SOURCE}}]]\n\t [[IsVariableInitialized_2/_7]]\n  (1) Failed precondition: Failed to allocate scratch buffer for device 0\n\t [[{{node _SOURCE}}]]\n0 successful operations.\n0 derived errors ignored.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-8e5f730b45f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0menv_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprev_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-0409bc2e298b>\u001b[0m in \u001b[0;36mchoose_action\u001b[0;34m(model, state)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mEXPLORE_COEF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mACTIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mACTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2959\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 216\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: 2 root error(s) found.\n  (0) Failed precondition: Failed to allocate scratch buffer for device 0\n\t [[{{node _SOURCE}}]]\n\t [[IsVariableInitialized_2/_7]]\n  (1) Failed precondition: Failed to allocate scratch buffer for device 0\n\t [[{{node _SOURCE}}]]\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sx3L1j9B5qn",
        "colab_type": "text"
      },
      "source": [
        "## Run simulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhSeQkSBB5qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if RECORD_VIDEO:\n",
        "    from gym.wrappers import Monitor\n",
        "    env_sim = Monitor(env, './video', force=True)\n",
        "else:\n",
        "    env_sim = env\n",
        "\n",
        "state = env_sim.reset()\n",
        "totalReward = 0\n",
        "\n",
        "UP_ACTION = 2\n",
        "DOWN_ACTION = 3\n",
        "\n",
        "for _ in range(1000):\n",
        "    env_sim.render()\n",
        "    \n",
        "    q = model.predict(state)\n",
        "    state, reward, done, _ = env_sim.step(np.argmax(q[0]))\n",
        "    totalReward += reward\n",
        "    if done:        \n",
        "        break\n",
        "    \n",
        "    if not RECORD_VIDEO:\n",
        "        time.sleep(1./30)\n",
        "        \n",
        "env_sim.close()\n",
        "\n",
        "print('Total reward = {}'.format(totalReward))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWteeIo8K2jR",
        "colab_type": "text"
      },
      "source": [
        "## Show the video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEb1-4mhEU0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_video():\n",
        "    import glob\n",
        "    import io\n",
        "    import base64\n",
        "    from IPython.display import HTML\n",
        "    from IPython import display as ipythondisplay\n",
        "\n",
        "    mp4list = glob.glob('video/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "            loop controls style=\"height: 400px;\">\n",
        "            <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "            </video>'''.format(encoded.decode('ascii'))))\n",
        "    else: \n",
        "        print(\"Could not find video\")\n",
        "    \n",
        "show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8eb7loItDM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dialog-Project-1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrumst/ML/blob/master/Dialog_Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzQLQ4w-FFBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%config IPComplater.greedy = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5JOECmlFDjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "DRIVE_MOUNT = './DRIVE/'\n",
        "DRIVE_MOUNT_MODEL_PATH = DRIVE_MOUNT + 'My Drive/colab_data/Dialogs/movie'\n",
        "drive.mount(DRIVE_MOUNT, force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L7H_WNXFNPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Bidirectional\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "INPUT_LENGTH = 20\n",
        "OUTPUT_LENGTH = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOrTGLS8Flll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir(DRIVE_MOUNT_MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfzKEWdBHlz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = open(DRIVE_MOUNT_MODEL_PATH + '/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "conv_lines = open(DRIVE_MOUNT_MODEL_PATH + '/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz4LyHkvHrfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a dictionary to map each line's id with its text\n",
        "id2line = {}\n",
        "for line in lines:\n",
        "    _line = line.split(' +++$+++ ')\n",
        "    if len(_line) == 5:\n",
        "        id2line[_line[0]] = _line[4]\n",
        "\n",
        "# Create a list of all of the conversations' lines' ids.\n",
        "convs = []\n",
        "for line in conv_lines[:-1]:\n",
        "    _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
        "    convs.append(_line.split(','))\n",
        "\n",
        "#id and conversation sample\n",
        "for k in convs[300]:\n",
        "    print (k, id2line[k])\n",
        "\n",
        "# Sort the sentences into questions (inputs) and answers (targets)\n",
        "questions = []\n",
        "answers = []\n",
        "for conv in convs:\n",
        "    for i in range(len(conv)-1):\n",
        "        questions.append(id2line[conv[i]])\n",
        "        answers.append(id2line[conv[i+1]])\n",
        "        \n",
        "# Compare lengths of questions and answers\n",
        "print(len(questions))\n",
        "print(len(answers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG5S22ZYJdTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for q in questions[:10]:\n",
        "    print(q)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri4Ws2nCIAZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|]\", \"\", text)\n",
        "#     text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "# Clean the data\n",
        "clean_questions = []\n",
        "for question in questions:\n",
        "    clean_questions.append(clean_text(question))\n",
        "clean_answers = []    \n",
        "for answer in answers:\n",
        "    clean_answers.append(clean_text(answer))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZcYCYyrKNdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove questions and answers that are shorter than 1 word and longer than 20 words.\n",
        "min_line_length = 2\n",
        "max_line_length = 20\n",
        "\n",
        "# Filter out the questions that are too short/long\n",
        "short_questions_temp = []\n",
        "short_answers_temp = []\n",
        "\n",
        "for i, question in enumerate(clean_questions):\n",
        "    if len(question.split()) >= min_line_length and len(question.split()) <= max_line_length:\n",
        "        short_questions_temp.append(question)\n",
        "        short_answers_temp.append(clean_answers[i])\n",
        "\n",
        "# Filter out the answers that are too short/long\n",
        "short_questions = []\n",
        "short_answers = []\n",
        "\n",
        "for i, answer in enumerate(short_answers_temp):\n",
        "    if len(answer.split()) >= min_line_length and len(answer.split()) <= max_line_length:\n",
        "        short_answers.append(answer)\n",
        "        short_questions.append(short_questions_temp[i])\n",
        "        \n",
        "print(len(short_questions))\n",
        "print(len(short_answers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1pfjagiKR9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r = np.random.randint(1,len(short_questions))\n",
        "\n",
        "for i in range(r, r+3):\n",
        "    print(short_questions[i])\n",
        "    print(short_answers[i])\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYLAK3jiKVey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "#choosing number of samples\n",
        "num_samples = 30000  # Number of samples to train on.\n",
        "short_questions = short_questions[:num_samples]\n",
        "short_answers = short_answers[:num_samples]\n",
        "#tokenizing the qns and answers\n",
        "short_questions_tok = [nltk.word_tokenize(sent) for sent in short_questions]\n",
        "short_answers_tok = [nltk.word_tokenize(sent) for sent in short_answers]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFUD1YhWN5nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train-validation split\n",
        "data_size = len(short_questions_tok)\n",
        "\n",
        "# We will use the first 0-80th %-tile (80%) of data for the training\n",
        "training_input  = short_questions_tok[:round(data_size*(80/100))]\n",
        "training_input  = [tr_input[::-1] for tr_input in training_input] #reverseing input seq for better performance\n",
        "training_output = short_answers_tok[:round(data_size*(80/100))]\n",
        "\n",
        "# We will use the remaining for validation\n",
        "validation_input = short_questions_tok[round(data_size*(80/100)):]\n",
        "validation_input  = [val_input[::-1] for val_input in validation_input] #reverseing input seq for better performance\n",
        "validation_output = short_answers_tok[round(data_size*(80/100)):]\n",
        "\n",
        "print('training size', len(training_input))\n",
        "print('validation size', len(validation_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK3NgNv4MDEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a dictionary for the frequency of the vocabulary\n",
        "# Create \n",
        "vocab = {}\n",
        "for question in short_questions_tok:\n",
        "    for word in question:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1\n",
        "\n",
        "for answer in short_answers_tok:\n",
        "    for word in answer:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1  \n",
        "\n",
        "# Remove rare words from the vocabulary.\n",
        "# We will aim to replace fewer than 5% of words with <UNK>\n",
        "# You will see this ratio soon.\n",
        "threshold = 15\n",
        "count = 0\n",
        "for k,v in vocab.items():\n",
        "    if v >= threshold:\n",
        "        count += 1\n",
        "\n",
        "print(\"Size of total vocab:\", len(vocab))\n",
        "print(\"Size of vocab we will use:\", count)\n",
        "\n",
        "#we will create dictionaries to provide a unique integer for each word.\n",
        "WORD_CODE_START = 1\n",
        "WORD_CODE_PADDING = 0\n",
        "\n",
        "\n",
        "word_num  = 2 #number 1 is left for WORD_CODE_START for model decoder later\n",
        "encoding = {}\n",
        "decoding = {1: 'START'}\n",
        "for word, count in vocab.items():\n",
        "    if count >= threshold: #get vocabularies that appear above threshold count\n",
        "        encoding[word] = word_num \n",
        "        decoding[word_num ] = word\n",
        "        word_num += 1\n",
        "\n",
        "#include unknown token for words not in dictionary\n",
        "decoding[len(encoding)+2] = '<UNK>'\n",
        "encoding['<UNK>'] = len(encoding)+2\n",
        "\n",
        "print(\"No. of vocab used:\", word_num)\n",
        "\n",
        "dict_size = word_num+1\n",
        "dict_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0FLVaHrNUIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(encoding, data, vector_size=20):\n",
        "    \"\"\"\n",
        "    :param encoding: encoding dict built by build_word_encoding()\n",
        "    :param data: list of strings\n",
        "    :param vector_size: size of each encoded vector\n",
        "    \"\"\"\n",
        "    transformed_data = np.zeros(shape=(len(data), vector_size))\n",
        "    for i in range(len(data)):\n",
        "        for j in range(min(len(data[i]), vector_size)):\n",
        "            try:\n",
        "                transformed_data[i][j] = encoding[data[i][j]]\n",
        "            except:\n",
        "                transformed_data[i][j] = encoding['<UNK>']\n",
        "    return transformed_data\n",
        "\n",
        "#encoding training set\n",
        "encoded_training_input = transform(encoding, training_input, vector_size=INPUT_LENGTH)\n",
        "encoded_training_output = transform(encoding, training_output, vector_size=OUTPUT_LENGTH)\n",
        "\n",
        "print('encoded_training_input', encoded_training_input.shape)\n",
        "print('encoded_training_output', encoded_training_output.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-2JBgk5OCrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encoding validation set\n",
        "encoded_validation_input = transform(encoding, validation_input, vector_size=INPUT_LENGTH)\n",
        "encoded_validation_output = transform(encoding, validation_output, vector_size=OUTPUT_LENGTH)\n",
        "\n",
        "print('encoded_validation_input', encoded_validation_input.shape)\n",
        "print('encoded_validation_output', encoded_validation_output.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUxJuaIKOLJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x74zHyyAOQSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import SimpleRNN\n",
        "\n",
        "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
        "decoder_input = Input(shape=(OUTPUT_LENGTH,))\n",
        "\n",
        "encoder = Embedding(dict_size, 128, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
        "encoder = LSTM(512, return_sequences=True, unroll=True)(encoder)\n",
        "encoder_last = encoder[:,-1,:]\n",
        "\n",
        "print('encoder', encoder)\n",
        "print('encoder_last', encoder_last)\n",
        "\n",
        "decoder = Embedding(dict_size, 128, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
        "decoder = LSTM(512, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n",
        "\n",
        "print('decoder', decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMERGRBZPAWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation, dot, concatenate\n",
        "\n",
        "# Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
        "# Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
        "attention = dot([decoder, encoder], axes=[2, 2])\n",
        "attention = Activation('softmax', name='attention')(attention)\n",
        "print('attention', attention)\n",
        "\n",
        "context = dot([attention, encoder], axes=[2,1])\n",
        "print('context', context)\n",
        "\n",
        "decoder_combined_context = concatenate([context, decoder])\n",
        "print('decoder_combined_context', decoder_combined_context)\n",
        "\n",
        "# Has another weight + tanh layer as described in equation (5) of the paper\n",
        "output = TimeDistributed(Dense(512, activation=\"tanh\"))(decoder_combined_context)\n",
        "output = TimeDistributed(Dense(dict_size, activation=\"softmax\"))(output)\n",
        "print('output', output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgn3DYzVPBQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sWXDZDaMr4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_encoder_input = encoded_training_input\n",
        "training_decoder_input = np.zeros_like(encoded_training_output)\n",
        "training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n",
        "training_decoder_input[:, 0] = WORD_CODE_START\n",
        "training_decoder_output = np.eye(dict_size)[encoded_training_output.astype('int')]\n",
        "\n",
        "validation_encoder_input = encoded_validation_input\n",
        "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
        "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
        "validation_decoder_input[:, 0] = WORD_CODE_START\n",
        "validation_decoder_output = np.eye(dict_size)[encoded_validation_output.astype('int')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D051w7nZMyxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
        "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
        "          #validation_split=0.05,\n",
        "          batch_size=64, epochs=100)\n",
        "\n",
        "model.save('model_attention.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DnQAhoANANB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction(raw_input):\n",
        "    clean_input = clean_text(raw_input)\n",
        "    input_tok = [nltk.word_tokenize(clean_input)]\n",
        "    input_tok = [input_tok[0][::-1]]  #reverseing input seq\n",
        "    encoder_input = transform(encoding, input_tok, 20)\n",
        "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
        "    decoder_input[:,0] = WORD_CODE_START\n",
        "    for i in range(1, OUTPUT_LENGTH):\n",
        "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
        "        decoder_input[:,i] = output[:,i]\n",
        "    return output\n",
        "\n",
        "def decode(decoding, vector):\n",
        "    \"\"\"\n",
        "    :param decoding: decoding dict built by word encoding\n",
        "    :param vector: an encoded vector\n",
        "    \"\"\"\n",
        "    text = ''\n",
        "    for i in vector:\n",
        "        if i == 0:\n",
        "            break\n",
        "        text += ' '\n",
        "        text += decoding[i]\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BROTAIR9NF4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(20):\n",
        "    seq_index = np.random.randint(1, len(short_questions))\n",
        "    output = prediction(short_questions[seq_index])\n",
        "    print ('Q:', short_questions[seq_index])\n",
        "    print ('A:', decode(decoding, output[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN-Face.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrumst/ML/blob/master/GAN_Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EwVJq9pK-XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%config IPComplater.greedy = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x63yz-CLOKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./DRIVE', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM7Ty6W_LeeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIoPQznyOiYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "DATA_SET_PATH_BASE = './DRIVE/My Drive/colab_data/lfw_funneled'\n",
        "IMG_LEN = 250\n",
        "IMG_HEIGHT = 250\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_paths = []\n",
        "base_img_paths = os.listdir(DATA_SET_PATH_BASE)\n",
        "for (i, img_dir) in enumerate(base_img_paths):\n",
        "    try:\n",
        "        img_dst = os.path.join(DATA_SET_PATH_BASE, img_dir)\n",
        "        if img_dst.find('.DS_Store') > -1 or img_dst.find('.txt') > -1:\n",
        "            continue\n",
        "        for img in os.listdir(img_dst):\n",
        "            img_paths.append(os.path.join(img_dst, img))\n",
        "    except:\n",
        "        print('err with %' % img_dir)\n",
        "    if i % 500 == 0:\n",
        "        print('readed dirs: {} from {}'.format(i, len(base_img_paths)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NQMal7Nrh6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "imgs = []\n",
        "for (i, img_path) in enumerate(img_paths[:200]):\n",
        "    img = Image.open(img_path)\n",
        "    imgs.append(np.array(img))\n",
        "    if i % 100 == 0:\n",
        "        print('Imported % imgs' % (i))\n",
        "\n",
        "print(len(imgs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXTVWAugp_W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_digits(samples):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    num = samples.shape[0]\n",
        "    for j in range(num):\n",
        "        ax = fig.add_subplot(8, 8, j+1)\n",
        "        ax.imshow(samples[j, ...].reshape(250, 250, 3), cmap='gray')\n",
        "        plt.xticks([]), plt.yticks([])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cKcrodzVCRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = 100\n",
        "NUM_EPOCHS = 500\n",
        "HALF_BATCH_SIZE = 16\n",
        "BATCH_SIZE = HALF_BATCH_SIZE * 2\n",
        "LEARNING_RATE = 0.0002\n",
        "\n",
        "imgs_ds = np.array(imgs).reshape(-1, 250, 250, 3)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(imgs_ds)\n",
        "train_ds = train_ds.shuffle(buffer_size=imgs_ds.shape[0])\n",
        "train_ds = train_ds.repeat(NUM_EPOCHS)\n",
        "train_ds = train_ds.batch(HALF_BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(LEARNING_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM7Ql4Q1chTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "generator = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256*10*10, activation=\"relu\"),\n",
        "    tf.keras.layers.Reshape((10, 10, 128)),\n",
        "    tf.keras.layers.UpSampling2D((5, 5)),    \n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
        "    tf.keras.layers.ReLU(),    \n",
        "    tf.keras.layers.UpSampling2D((5, 5)),    \n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
        "    tf.keras.layers.ReLU(),    \n",
        "    tf.keras.layers.Conv2D(3, (3, 3), padding=\"same\", activation='tanh'),\n",
        "])\n",
        "\n",
        "discriminator = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "    tf.keras.layers.LeakyReLU(0.2),\n",
        "    tf.keras.layers.Dropout(0.25),    \n",
        "    tf.keras.layers.Conv2D(64, kernel_size=3, strides=(2, 2), padding=\"same\"),\n",
        "    tf.keras.layers.ZeroPadding2D(padding=((0, 1), (0, 1))),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(128, kernel_size=3, strides=(2, 2), padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(256, kernel_size=3, strides=(1, 1), padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation=None),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6qGEA7wci4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for step, true_images in enumerate(train_ds):\n",
        "    \n",
        "    # Train Discriminator\n",
        "    \n",
        "    noise = np.random.normal(0, 1, (HALF_BATCH_SIZE, INPUT_DIM)).astype(np.float32)\n",
        "    syntetic_images = generator.predict(noise)\n",
        "    x_combined = np.concatenate((\n",
        "        true_images, \n",
        "        syntetic_images))\n",
        "    y_combined = np.concatenate((\n",
        "        np.ones((HALF_BATCH_SIZE, 1)), \n",
        "        np.zeros((HALF_BATCH_SIZE, 1))))\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = discriminator(x_combined, training=True)\n",
        "        d_loss_value = tf.losses.sigmoid_cross_entropy(y_combined, logits)\n",
        "    grads = tape.gradient(d_loss_value, discriminator.variables)\n",
        "    optimizer.apply_gradients(zip(grads, discriminator.variables))\n",
        "    \n",
        "    # Train Generator\n",
        "    \n",
        "    noise = np.random.normal(0, 1, (BATCH_SIZE, INPUT_DIM)).astype(np.float32)\n",
        "    y_mislabled = np.ones((BATCH_SIZE, 1))\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        syntetic = generator(noise, training=True)\n",
        "        logits = discriminator(syntetic, training=False)\n",
        "        g_loss_value = tf.losses.sigmoid_cross_entropy(y_mislabled, logits)\n",
        "    grads = tape.gradient(g_loss_value, generator.variables)\n",
        "    optimizer.apply_gradients(zip(grads, generator.variables))\n",
        "    \n",
        "    # Check intermediate results\n",
        "    \n",
        "    if step % 200 == 0:\n",
        "        print(\"[Step %2d] D Loss: %.4f; G Loss: %.4f\" % (\n",
        "            step, d_loss_value.numpy(), g_loss_value.numpy()))\n",
        "        noise = np.random.normal(0, 1, (8, INPUT_DIM)).astype(np.float32)\n",
        "        syntetic_images = generator.predict(noise)\n",
        "        plot_digits(syntetic_images)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i5jXcG9mcMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}